pip install -r requirements.txt
streamlit run app.py

import streamlit as st
import pandas as pd
import numpy as np
import altair as alt
from io import StringIO
from typing import List, Tuple

st.set_page_config(page_title="êµ­ê°€ë³„ MBTI ë¶„í¬ ë·°ì–´", page_icon="ğŸ§­", layout="wide")

# -----------------------------
# ìœ í‹¸í•¨ìˆ˜
# -----------------------------
ENCODINGS_TO_TRY = ["utf-8", "utf-8-sig", "cp949", "euc-kr"]

MBTI_TYPES = [
    "INTJ","INTP","ENTJ","ENTP","INFJ","INFP","ENFJ","ENFP",
    "ISTJ","ISFJ","ESTJ","ESFJ","ISTP","ISFP","ESTP","ESFP"
]

def detect_mbti_columns(df: pd.DataFrame) -> List[str]:
    """ì»¬ëŸ¼ëª…ì—ì„œ MBTI 16ìœ í˜• ì»¬ëŸ¼ ìë™ íƒì§€"""
    mbti_cols = []
    for col in df.columns:
        norm = str(col).strip().lower().replace("%","").replace(" ","").replace("_","")
        for t in MBTI_TYPES:
            if norm == t.lower() or norm.startswith(t.lower()):
                mbti_cols.append(col)
                break
    # ìˆœì„œ ë³´ì¡´ ì¤‘ë³µ ì œê±°
    seen = set()
    mbti_cols = [c for c in mbti_cols if not (c in seen or seen.add(c))]
    return mbti_cols

def to_numeric_clean(s: pd.Series) -> pd.Series:
    """ë¬¸ìì—´ %/ì‰¼í‘œ ì œê±° í›„ ìˆ«ì ë³€í™˜"""
    if s.dtype.kind in "biufc":
        return s
    cleaned = (
        s.astype(str)
         .str.replace("%","",regex=False)
         .str.replace(",","",regex=False)
         .replace({"nan": np.nan})
    )
    return pd.to_numeric(cleaned, errors="coerce")

def normalize_unit_to_percent(df: pd.DataFrame, mbti_cols: List[str]) -> Tuple[pd.DataFrame, str]:
    """
    MBTI í•©ê³„ í‰ê· ì„ ë³´ê³  0~1(ë¹„ìœ¨)ì¸ì§€ 0~100(í¼ì„¼íŠ¸)ì¸ì§€ íŒë³„.
    ëª¨ë‘ 'í¼ì„¼íŠ¸(0~100)'ë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜.
    """
    tmp = df.copy()
    for c in mbti_cols:
        tmp[c] = to_numeric_clean(tmp[c])
    tmp["__sum__"] = tmp[mbti_cols].sum(axis=1, skipna=True)
    mean_sum = tmp["__sum__"].mean()

    if 0.95 <= mean_sum <= 1.05:       # ë¹„ìœ¨
        for c in mbti_cols:
            tmp[c] = tmp[c] * 100.0
        unit = "ë¹„ìœ¨(0~1) â†’ í¼ì„¼íŠ¸(0~100)ë¡œ ë³€í™˜"
    else:
        unit = "í¼ì„¼íŠ¸(0~100) ê·¸ëŒ€ë¡œ ì‚¬ìš©"

    tmp.drop(columns=["__sum__"], inplace=True)
    return tmp, unit

def robust_read_csv(uploaded_file_or_path) -> Tuple[pd.DataFrame, str]:
    """ì—¬ëŸ¬ ì¸ì½”ë”© ì‹œë„ ë¡œë”"""
    last_err = None
    for enc in ENCODINGS_TO_TRY:
        try:
            df = pd.read_csv(uploaded_file_or_path, encoding=enc)
            return df, enc
        except Exception as e:
            last_err = e
    raise RuntimeError(f"CSVë¥¼ ì½ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë§ˆì§€ë§‰ ì˜¤ë¥˜: {last_err}")

@st.cache_data(show_spinner=False)
def load_data(file_bytes: bytes | None, local_path: str | None) -> Tuple[pd.DataFrame, str]:
    """ì—…ë¡œë“œ íŒŒì¼ ìš°ì„ , ì—†ìœ¼ë©´ ë¡œì»¬ ê²½ë¡œ ì‹œë„"""
    if file_bytes is not None:
        # ì—…ë¡œë“œ íŒŒì¼ì€ ë°”ì´íŠ¸ â†’ StringIOë¡œ ë³€í™˜í•˜ì—¬ ì¸ì½”ë”© íƒì§€
        content = file_bytes.decode("utf-8", errors="ignore")
        # ë¨¼ì € utf-8 ì‹œë„, ì‹¤íŒ¨ ì‹œ ë‹¤ì–‘í•œ ì¸ì½”ë”© ì¬ì‹œë„
        try:
            return pd.read_csv(StringIO(content)), "utf-8*"
        except Exception:
            pass
        # ì¬ì‹œë„
        return robust_read_csv(StringIO(content))
    if local_path:
        return robust_read_csv(local_path)
    raise RuntimeError("ë°ì´í„° ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. CSVë¥¼ ì—…ë¡œë“œí•˜ê±°ë‚˜ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.")

def guess_country_col(df: pd.DataFrame, mbti_cols: List[str]) -> str | None:
    """êµ­ê°€/ì‹ë³„ì ì»¬ëŸ¼ ì¶”ì •: MBTI ì»¬ëŸ¼ì´ ì•„ë‹Œ ê²ƒ ì¤‘ ìš°ì„ ìˆœìœ„ë¡œ íƒìƒ‰"""
    candidates = [c for c in df.columns if c not in mbti_cols]
    # ìš°ì„ ìˆœìœ„: Country, country, êµ­ê°€, Nation, Name ë“±
    priority = ["Country","country","êµ­ê°€","Nation","nation","Name","name","ì§€ì—­","ì§€ì—­ëª…"]
    for p in priority:
        if p in df.columns and p not in mbti_cols:
            return p
    return candidates[0] if candidates else None

def tidy_country_row(row: pd.Series, mbti_cols: List[str]) -> pd.DataFrame:
    """í•œ êµ­ê°€ í–‰ì„ ì„¸ë¡œí˜•(Type, Percent)ìœ¼ë¡œ ë³€í™˜í•˜ê³  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬"""
    data = []
    for c in mbti_cols:
        val = to_numeric_clean(pd.Series([row[c]])).iloc[0]
        data.append((c, val))
    out = pd.DataFrame(data, columns=["Type", "Percent"])
    out = out.sort_values("Percent", ascending=False).reset_index(drop=True)
    return out

# -----------------------------
# ì‚¬ì´ë“œë°” & ë°ì´í„° ë¡œë“œ
# -----------------------------
st.title("ğŸ§­ êµ­ê°€ë³„ MBTI ë¶„í¬ ë·°ì–´")
st.caption("CSVì—ì„œ êµ­ê°€ë¥¼ ì„ íƒí•˜ë©´, í•´ë‹¹ êµ­ê°€ì˜ MBTI 16ìœ í˜• ë¹„ìœ¨ì„ ë‚´ë¦¼ì°¨ìˆœìœ¼ë¡œ ë³´ì—¬ì¤ë‹ˆë‹¤. (ë‹¨ìœ„ ìë™ ì¸ì‹)")

with st.sidebar:
    st.header("ğŸ“‚ ë°ì´í„° ì†ŒìŠ¤")
    uploaded = st.file_uploader("MBTI CSV ì—…ë¡œë“œ", type=["csv"])
    use_local = st.toggle("ë¡œì»¬ ê¸°ë³¸ ê²½ë¡œ ì‚¬ìš©(ìˆì„ ë•Œ)", value=True)
    local_path = "countriesMBTI_16types.csv" if use_local else None
    st.markdown("- ì»¬ëŸ¼ ì˜ˆì‹œ: `Country`, `INFJ`, `ISFJ`, ..., `ESFJ`")

try:
    df, used_encoding = load_data(uploaded.getvalue() if uploaded else None, local_path)
except Exception as e:
    st.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
    st.stop()

mbti_cols = detect_mbti_columns(df)
if len(mbti_cols) != 16:
    st.warning(f"MBTI ì»¬ëŸ¼ ê°ì§€ ìˆ˜: {len(mbti_cols)} (ì˜ˆìƒ 16). ì»¬ëŸ¼ëª…ì„ í™•ì¸í•´ ì£¼ì„¸ìš”.\nê°ì§€ë¨: {mbti_cols}")

df_norm, unit_info = normalize_unit_to_percent(df, mbti_cols)
country_col = guess_country_col(df_norm, mbti_cols)

col_l, col_r = st.columns([2, 1])
with col_l:
    st.subheader("ë°ì´í„° ê°œìš”")
    st.write(f"- í–‰/ì—´: **{df_norm.shape[0]} x {df_norm.shape[1]}**, ì¸ì½”ë”©: **{used_encoding}**")
    st.write(f"- MBTI ì»¬ëŸ¼(16): {', '.join(mbti_cols)}")
    st.write(f"- ë‹¨ìœ„ ì²˜ë¦¬: **{unit_info}** â†’ ì‹œê°í™”/í‘œì‹œëŠ” **í¼ì„¼íŠ¸(%)** ê¸°ì¤€")
with col_r:
    st.dataframe(df_norm.head(10), use_container_width=True)

if not country_col:
    st.error("êµ­ê°€(ì‹ë³„ì) ì»¬ëŸ¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. 'Country' ë˜ëŠ” êµ­ê°€ëª…ì„ ë‹´ì€ ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    st.stop()

# êµ­ê°€ ì„ íƒ
countries = df_norm[country_col].astype(str).dropna().unique().tolist()
countries.sort()
selected = st.selectbox("êµ­ê°€ ì„ íƒ", options=countries, index=0)

# ì„ íƒ í–‰ ì¶”ì¶œ
row = df_norm.loc[df_norm[country_col].astype(str) == str(selected)]
if row.empty:
    st.error("ì„ íƒí•œ êµ­ê°€ì˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    st.stop()

row = row.iloc[0]
tidy_df = tidy_country_row(row, mbti_cols)

# í•©ê³„/ì˜¤ì°¨ ì•ˆë‚´
sum_percent = float(np.nansum(tidy_df["Percent"].values))
warn = ""
if not (99.0 <= sum_percent <= 101.0):
    warn = f"âš ï¸ í•©ê³„ê°€ {sum_percent:.2f}% ì…ë‹ˆë‹¤(ì´ìƒì¹˜ì¼ ìˆ˜ ìˆìŒ)."
else:
    warn = f"âœ… í•©ê³„: {sum_percent:.2f}% (ì •ìƒ ë²”ìœ„)"

st.markdown(f"### ğŸ‡ºğŸ‡³ {selected} â€” MBTI ë¶„í¬ (ë‚´ë¦¼ì°¨ìˆœ)")
st.caption(warn)

# ì‹œê°í™”
chart = (
    alt.Chart(tidy_df)
    .mark_bar()
    .encode(
        x=alt.X("Percent:Q", title="ë¹„ìœ¨(%)"),
        y=alt.Y("Type:N", sort="-x", title="MBTI ìœ í˜•"),
        tooltip=[alt.Tooltip("Type:N", title="ìœ í˜•"),
                 alt.Tooltip("Percent:Q", title="ë¹„ìœ¨(%)", format=".2f")]
    )
    .properties(height=420)
)

st.altair_chart(chart, use_container_width=True)

# í‘œ (í¼ì„¼íŠ¸ í¬ë§·)
fmt_df = tidy_df.copy()
fmt_df["ë¹„ìœ¨(%)"] = fmt_df["Percent"].map(lambda v: f"{v:.2f}")
fmt_df = fmt_df[["Type","ë¹„ìœ¨(%)"]]
st.dataframe(fmt_df, use_container_width=True, hide_index=True)

# ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
csv_bytes = tidy_df.to_csv(index=False).encode("utf-8-sig")
st.download_button(
    label="â¬‡ï¸ ì´ êµ­ê°€ì˜ MBTI ë¶„í¬ CSV ë‹¤ìš´ë¡œë“œ",
    data=csv_bytes,
    file_name=f"{selected}_MBTI_distribution.csv",
    mime="text/csv"
)

# ì¬ë¯¸ ìš”ì†Œ(ì„ íƒ ì‹œ 1íšŒ)
if st.button("ğŸˆ ì¶•í•˜ í’ì„  í•œë²ˆ!"):
    st.balloons()
